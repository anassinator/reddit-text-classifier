{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "raw_traininput = pd.read_csv('../data/train_input.csv')\n",
    "raw_trainoutput = pd.read_csv('../data/train_output.csv')\n",
    "\n",
    "raw_testinput = pd.read_csv('../data/test_input.csv')\n",
    "\n",
    "traininput_size = raw_traininput.shape[0]\n",
    "testinput_size = raw_testinput.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_data(data):\n",
    "    data_size = data.shape[0]\n",
    "    tag_regex = '<.*?>|\\n'\n",
    "    \n",
    "    cleaned_data = pd.DataFrame([ re.sub(tag_regex, '', data['conversation'][i]) \\\n",
    "                    for i in range(data_size) ], columns = {('conversation')})\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165000, 2)\n",
      "0.966666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     hockey       0.98      0.98      0.98      4170\n",
      "     movies       0.98      0.99      0.99      4510\n",
      "        nba       0.99      0.97      0.98      3696\n",
      "       news       0.94      0.91      0.92      4256\n",
      "        nfl       0.98      0.98      0.98      3978\n",
      "   politics       0.93      0.95      0.94      3943\n",
      "     soccer       0.99      0.99      0.99      4299\n",
      "  worldnews       0.95      0.96      0.95      4148\n",
      "\n",
      "avg / total       0.97      0.97      0.97     33000\n",
      "\n",
      "[[4086   15   24    3   24    1   14    3]\n",
      " [   5 4474    1   11    1    6    3    9]\n",
      " [  40   18 3575    8   31    3   18    3]\n",
      " [   1   17    3 3879   13  180    2  161]\n",
      " [  27    5   18    7 3911    3    6    1]\n",
      " [   2    1    1  148    1 3751    1   38]\n",
      " [  16    5    5    4    8    2 4248   11]\n",
      " [   2    8    0   85    0   67   10 3976]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clean_traininput = raw_traininput\n",
    "print clean_traininput.shape\n",
    "\n",
    "cvec = CountVectorizer(analyzer='word', \n",
    "                       stop_words = 'english',\n",
    "                       ngram_range = (1,5))\n",
    "\n",
    "classification = Pipeline([('vectorizer', cvec),\n",
    "                           ('transformer', TfidfTransformer()),\n",
    "                           ('classifier', LinearSVC(C=3, loss='hinge'))])\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(clean_traininput['conversation'], \n",
    "                                                                    raw_trainoutput['category'], \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=105)\n",
    "\n",
    "classification = classification.fit(train_data, train_labels)\n",
    "predicted = classification.predict(test_data)\n",
    "print np.mean(predicted == test_labels)\n",
    "print metrics.classification_report(test_labels, predicted)\n",
    "print metrics.confusion_matrix(test_labels, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53218, 2)\n"
     ]
    }
   ],
   "source": [
    "clean_testinput = raw_testinput\n",
    "print clean_testinput.shape\n",
    "\n",
    "cvec2 = CountVectorizer(analyzer='word', \n",
    "                       stop_words = 'english',\n",
    "                       ngram_range = (1,5))\n",
    "\n",
    "classification2 = Pipeline([('vectorizer', cvec2),\n",
    "                           ('transformer', TfidfTransformer()),\n",
    "                           ('classifier', LinearSVC(C=3, loss='hinge'))])\n",
    "\n",
    "classification2 = classification2.fit(clean_traininput['conversation'], raw_trainoutput['category'])\n",
    "predicted2 = classification2.predict(clean_testinput['conversation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'category' : predicted2})\n",
    "result.to_csv('../data/test_predict_LSVM_5gramC3.csv', index = True, header = True, index_label = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53218, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_testinput.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51706.07662"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.97159*53218"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
