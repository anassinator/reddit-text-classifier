{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "raw_traininput = pd.read_csv('../data/train_input.csv')\n",
    "raw_trainoutput = pd.read_csv('../data/train_output.csv')\n",
    "\n",
    "raw_testinput = pd.read_csv('../data/test_input.csv')\n",
    "\n",
    "traininput_size = raw_traininput.shape[0]\n",
    "testinput_size = raw_testinput.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_data(data):\n",
    "    data_size = data.shape[0]\n",
    "    tag_regex = '<.*?>|\\n'\n",
    "    \n",
    "    cleaned_data = pd.DataFrame([ re.sub(tag_regex, '', data['conversation'][i]) \\\n",
    "                    for i in range(data_size) ], columns = {('conversation')})\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165000, 2)\n",
      "Detailed classification report:\n",
      "0.966393939394\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     hockey       0.98      0.98      0.98      4170\n",
      "     movies       0.98      0.99      0.99      4510\n",
      "        nba       0.99      0.97      0.98      3696\n",
      "       news       0.94      0.91      0.92      4256\n",
      "        nfl       0.98      0.98      0.98      3978\n",
      "   politics       0.93      0.95      0.94      3943\n",
      "     soccer       0.99      0.99      0.99      4299\n",
      "  worldnews       0.95      0.96      0.95      4148\n",
      "\n",
      "avg / total       0.97      0.97      0.97     33000\n",
      "\n",
      "[[4085   15   24    3   25    1   14    3]\n",
      " [   6 4473    1   11    1    6    3    9]\n",
      " [  40   18 3576    8   31    3   18    2]\n",
      " [   1   17    3 3874   13  183    2  163]\n",
      " [  28    5   18    7 3910    3    6    1]\n",
      " [   2    1    1  150    1 3749    1   38]\n",
      " [  16    5    5    4    8    2 4248   11]\n",
      " [   2    8    0   85    0   67   10 3976]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tuned_parameters = [{'C': [1, 2, 3, 4, 5, 6]}]\n",
    "\n",
    "clean_traininput = raw_traininput\n",
    "print clean_traininput.shape\n",
    "\n",
    "cvec = CountVectorizer(analyzer='word', \n",
    "                       stop_words = 'english',\n",
    "                       ngram_range = (1,5))\n",
    "\n",
    "classification = Pipeline([('vectorizer', cvec),\n",
    "                           ('transformer', TfidfTransformer()),\n",
    "                           ('classifier', GridSearchCV(LinearSVC(loss='hinge'), \n",
    "                                                       tuned_parameters, cv=3,\n",
    "                                                       scoring='precision_macro'))])\n",
    "\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(clean_traininput['conversation'], \n",
    "                                                                    raw_trainoutput['category'], \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=105)\n",
    "\n",
    "classification = classification.fit(train_data, train_labels)\n",
    "\n",
    "predicted = classification.predict(test_data)\n",
    "print(\"Detailed classification report:\")\n",
    "print np.mean(predicted == test_labels)\n",
    "print metrics.classification_report(test_labels, predicted)\n",
    "print metrics.confusion_matrix(test_labels, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 2}\n",
      "Grid scores on development set:\n",
      "0.95645 (+/-0.001) for {'C': 1}\n",
      "0.95875 (+/-0.001) for {'C': 2}\n",
      "0.95867 (+/-0.001) for {'C': 3}\n",
      "0.95867 (+/-0.001) for {'C': 4}\n",
      "0.95867 (+/-0.001) for {'C': 5}\n",
      "0.95866 (+/-0.001) for {'C': 6}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print(classification.named_steps['classifier'].best_params_)\n",
    "print(\"Grid scores on development set:\")\n",
    "means = classification.named_steps['classifier'].cv_results_['mean_test_score']\n",
    "stds = classification.named_steps['classifier'].cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, classification.named_steps['classifier'].cv_results_['params']):\n",
    "    print(\"%0.5f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53218, 2)\n"
     ]
    }
   ],
   "source": [
    "clean_testinput = raw_testinput\n",
    "print clean_testinput.shape\n",
    "\n",
    "cvec2 = CountVectorizer(analyzer='word', \n",
    "                       stop_words = 'english',\n",
    "                       ngram_range = (1,3))\n",
    "\n",
    "classification2 = Pipeline([('vectorizer', cvec2),\n",
    "                           ('transformer', TfidfTransformer()),\n",
    "                           ('classifier', LinearSVC(loss='hinge'))])\n",
    "\n",
    "classification2 = classification2.fit(clean_traininput['conversation'], raw_trainoutput['category'])\n",
    "predicted2 = classification2.predict(clean_testinput['conversation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'category' : predicted2})\n",
    "result.to_csv('../data/test_predict.csv', index = True, header = True, index_label = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53218, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_testinput.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
